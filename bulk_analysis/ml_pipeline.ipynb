{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d816fc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis script:\\n1. Loads metadata (clinical or sample labels).\\n2. Loads CDR3 data from hundreds of parquet files generated by your CDR3 extraction algorithm (aho_6RF or ROAR).\\n3. Builds a feature matrix where:\\neach row = a sample\\neach column = one CDR3 sequence\\nvalues = counts of that sequence\\n4. Keeps only the \"top N\" most informative CDR3 sequences.\\n5. Runs machine-learning models (LogReg, RF, SVM, KNN, XGBoost).\\n6. Performs SMOTE to balance the classes.\\n7. Evaluates models (Balanced accuracy, Precision, Recall, F1, ROC-AUC).\\n8. Runs feature selection methods (ANOVA, Mutual Info, RFE).\\n9.  Finds the best k features and best selector.\\n10. Saes results to cache folders, so you don’t repeat expensive computations.\\n\\n11. Uses logging to write everything to a log file\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script:\n",
    "1. Loads metadata (clinical or sample labels).\n",
    "2. Loads CDR3 data from hundreds of parquet files generated by your CDR3 extraction algorithm (aho_6RF or ROAR).\n",
    "3. Builds a feature matrix where:\n",
    "each row = a sample\n",
    "each column = one CDR3 sequence\n",
    "values = counts of that sequence\n",
    "4. Keeps only the \"top N\" most informative CDR3 sequences.\n",
    "5. Runs machine-learning models (LogReg, RF, SVM, KNN, XGBoost).\n",
    "6. Performs SMOTE to balance the classes.\n",
    "7. Evaluates models (Balanced accuracy, Precision, Recall, F1, ROC-AUC).\n",
    "8. Runs feature selection methods (ANOVA, Mutual Info, RFE).\n",
    "9.  Finds the best k features and best selector.\n",
    "10. Saes results to cache folders, so you don’t repeat expensive computations.\n",
    "\n",
    "11. Uses logging to write everything to a log file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b81600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 09:37:38 | INFO | Logging to: /home/dsi/linoym/airrport/Thesis/bulk_analysis/logs/ml_pipeline_biopsy_aho_6RF_20251203_093738.log\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ML pipeline for AIRRPORT CDR3 features with enhanced models and plots\n",
    "Author: Linoy Menda\n",
    "Date: 2025-12-02\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from hashlib import sha1\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "\n",
    "# --- Configuration ---\n",
    "RESOURCE = \"biopsy\"  # biopsy or blood\n",
    "ALGO_VERSION = 'aho_6RF'\n",
    "RESOURCE = RESOURCE.lower()\n",
    "\n",
    "BASE_PATH = Path(\"/dsi/efroni-lab/AIRRPORT/bulk_IBD\")\n",
    "RESOURCE_PATHS = {\n",
    "    \"biopsy\": BASE_PATH / \"biopsy/CDR3_match_results\" / ALGO_VERSION,\n",
    "    \"blood\": BASE_PATH / \"blood/CDR3_match_results\" / ALGO_VERSION,\n",
    "}\n",
    "\n",
    "if RESOURCE not in RESOURCE_PATHS:\n",
    "    raise ValueError(f\"Invalid RESOURCE: {RESOURCE}. Must be one of {list(RESOURCE_PATHS.keys())}.\")\n",
    "if ALGO_VERSION not in ['aho_6RF', 'roar']:\n",
    "    raise ValueError(f\"Invalid ALGO_VERSION: {ALGO_VERSION}. Must be 'aho_6RF' or 'roar'.\")\n",
    "\n",
    "ALGO_RESULTS_PATH = RESOURCE_PATHS[RESOURCE]\n",
    "METADATA_FILE = ALGO_RESULTS_PATH / f\"metadata_IBD{'_blood' if RESOURCE=='blood' else ''}.csv\"\n",
    "\n",
    "# --- Logging ---\n",
    "logs_dir = Path.cwd() / \"logs\"\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_file = logs_dir / f\"ml_pipeline_{RESOURCE}_{ALGO_VERSION}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logger = logging.getLogger(\"airrport.ml_pipeline\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "if logger.handlers:\n",
    "    for h in list(logger.handlers):\n",
    "        logger.removeHandler(h)\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "console_handler = logging.StreamHandler()\n",
    "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\",\"%Y-%m-%d %H:%M:%S\")\n",
    "file_handler.setFormatter(fmt)\n",
    "console_handler.setFormatter(fmt)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "logger.info(f\"Logging to: {log_file}\")\n",
    "\n",
    "# --- Cache ---\n",
    "CACHE_ROOT = Path.cwd() / \"cache\"\n",
    "CACHE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def _hash_bytes(b: bytes) -> str:\n",
    "    return sha1(b).hexdigest()[:12]\n",
    "\n",
    "def _dir_fingerprint(path: Path, pattern=\"*.parquet\") -> str:\n",
    "    files = sorted(path.glob(pattern))\n",
    "    h = sha1()\n",
    "    for f in files:\n",
    "        try:\n",
    "            stat = f.stat()\n",
    "            h.update(f.name.encode())\n",
    "            h.update(str(stat.st_size).encode())\n",
    "            h.update(str(int(stat.st_mtime)).encode())\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return h.hexdigest()[:12]\n",
    "\n",
    "def _file_fingerprint(f: Path) -> str:\n",
    "    if not f.exists():\n",
    "        return \"no_meta\"\n",
    "    stat = f.stat()\n",
    "    return _hash_bytes(f\"{f.name}:{stat.st_size}:{int(stat.st_mtime)}\".encode())\n",
    "\n",
    "def data_fingerprint() -> str:\n",
    "    p_fp = _dir_fingerprint(ALGO_RESULTS_PATH, \"*.parquet\")\n",
    "    m_fp = _file_fingerprint(METADATA_FILE)\n",
    "    return _hash_bytes(f\"{RESOURCE}|{ALGO_VERSION}|{str(ALGO_RESULTS_PATH)}|{p_fp}|{m_fp}\".encode())\n",
    "\n",
    "def get_cache_dir(target_column: str) -> Path:\n",
    "    fp = data_fingerprint()\n",
    "    d = CACHE_ROOT / RESOURCE / ALGO_VERSION / target_column / fp\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def save_pickle(p: Path, obj):\n",
    "    with open(p, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(p: Path):\n",
    "    with open(p, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_json(p: Path, obj):\n",
    "    with open(p, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def try_load(p: Path):\n",
    "    return p.exists(), (load_pickle(p) if p.suffix == \".pkl\" else (pd.read_csv(p) if p.suffix == \".csv\" else json.load(open(p)) if p.suffix == \".json\" else None))\n",
    "\n",
    "# --- Metadata / CDR3 Processing ---\n",
    "def analysis_for_target(target_column):\n",
    "    logger.info(f\"Processing target column: {target_column}\")\n",
    "    metadata_df = pd.read_csv(METADATA_FILE)\n",
    "    if target_column not in metadata_df.columns:\n",
    "        logger.warning(f\"Column '{target_column}' not found in metadata.\")\n",
    "        exit(1)\n",
    "    if metadata_df[target_column].isna().sum() > len(metadata_df) * 0.5:\n",
    "        logger.warning(f\"Column '{target_column}' has >50% missing values.\")\n",
    "        exit(1)\n",
    "    unique_vals = metadata_df[target_column].dropna().unique()\n",
    "    if 1 < len(unique_vals) <= 4:\n",
    "        logger.info(f\"Target '{target_column}' has {len(unique_vals)} unique values: {unique_vals}\")\n",
    "    return metadata_df\n",
    "\n",
    "def read_parquet_file(parquet_file_path):\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    sample_name = parquet_file_path.stem.replace('matched_', '').replace('.dedup', '')\n",
    "    cdr3_counts = df.groupby('CDR3_match')['count'].sum().to_dict()\n",
    "    return sample_name, cdr3_counts\n",
    "\n",
    "def load_cdr3_data(target_column, use_cache=True, parallel=True):\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "    cache_file = cache_dir / \"cdr3_data.pkl\"\n",
    "    if use_cache and cache_file.exists():\n",
    "        logger.info(f\"Loading cached CDR3 data from {cache_file}\")\n",
    "        return load_pickle(cache_file)\n",
    "\n",
    "    parquet_files = list(ALGO_RESULTS_PATH.glob(\"*.parquet\"))\n",
    "    logger.info(f\"Found {len(parquet_files)} parquet files\")\n",
    "    cdr3_data_from_all_parquets = {}\n",
    "\n",
    "    if parallel:\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            for sample_name, cdr3_counts in executor.map(read_parquet_file, parquet_files):\n",
    "                cdr3_data_from_all_parquets[sample_name] = cdr3_counts\n",
    "    else:\n",
    "        for i, parquet_file_path in enumerate(parquet_files, 1):\n",
    "            sample_name, cdr3_counts = read_parquet_file(parquet_file_path)\n",
    "            cdr3_data_from_all_parquets[sample_name] = cdr3_counts\n",
    "            if i % 100 == 0:\n",
    "                logger.info(f\"Processed file {i}/{len(parquet_files)}\")\n",
    "\n",
    "    save_pickle(cache_file, cdr3_data_from_all_parquets)\n",
    "    return cdr3_data_from_all_parquets\n",
    "\n",
    "def create_feature_matrix_with_metdata(metadata, cdr3_data, top_n=600, target_column=None, use_cache=True):\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "    feat_cache = cache_dir / f\"features_top{top_n}.pkl\"\n",
    "    if use_cache and feat_cache.exists():\n",
    "        logger.info(f\"Loading cached features from {feat_cache}\")\n",
    "        return load_pickle(feat_cache)\n",
    "\n",
    "    rows = [(s, seq, c) for s, d in cdr3_data.items() for seq, c in d.items() if isinstance(seq,str) and seq.startswith('C')]\n",
    "    df_long = pd.DataFrame(rows, columns=['sample','sequence','count'])\n",
    "    seq_counts_across_samples = df_long.groupby('sequence')['sample'].nunique()\n",
    "    top_sequences = seq_counts_across_samples.nlargest(top_n).index\n",
    "    df_long = df_long[df_long['sequence'].isin(top_sequences)]\n",
    "    x_matrix_feature = df_long.pivot_table(index='sample', columns='sequence', values='count', fill_value=0)\n",
    "\n",
    "    metadata_filtered = metadata[metadata['Run'].isin(x_matrix_feature.index)].copy()\n",
    "    metadata_filtered = metadata_filtered.set_index('Run').loc[x_matrix_feature.index]\n",
    "    y_metadata_target = metadata_filtered[target_column].values\n",
    "\n",
    "    save_pickle(feat_cache, (x_matrix_feature, y_metadata_target))\n",
    "    logger.info(f\"Saved feature cache to {feat_cache}\")\n",
    "    return x_matrix_feature, y_metadata_target\n",
    "\n",
    "# --- Plotting helpers ---\n",
    "def plot_model_bars(results_df: pd.DataFrame, cache_dir: Path, top_n: int):\n",
    "    df = results_df.copy().sort_values(by=\"Balanced Accuracy\", ascending=False)\n",
    "\n",
    "    # --- Balanced Accuracy plot ---\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    palette = sns.color_palette(\"pastel\", n_colors=len(df))\n",
    "    bars = plt.bar(df['Model'], df['Balanced Accuracy'], color=palette)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0,1)\n",
    "    plt.ylabel(\"Balanced Accuracy\")\n",
    "    plt.title(f\"Balanced Accuracy by model (top{top_n} features)\")\n",
    "\n",
    "    # Add values on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.02, f\"{height:.3f}\",\n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cache_dir / f\"balanced_accuracy_top{top_n}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # --- ROC AUC plot ---\n",
    "    if 'ROC AUC' in df.columns:\n",
    "        plt.figure(figsize=(8,4.5))\n",
    "        roc_values = df['ROC AUC'].fillna(0)\n",
    "        bars = plt.bar(df['Model'], roc_values, color=palette)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(0,1)\n",
    "        plt.ylabel(\"ROC AUC (NaN=0)\")\n",
    "        plt.title(f\"ROC AUC by model (top{top_n} features)\")\n",
    "\n",
    "        # Add ROC AUC values on top\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.02, f\"{height:.3f}\",\n",
    "                     ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(cache_dir / f\"roc_auc_top{top_n}.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, cache_dir: Path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cache_dir / f\"confusion_matrix_{model_name.replace(' ','_')}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(clf, feature_names, model_name, cache_dir: Path, top_n=30):\n",
    "    if not hasattr(clf, 'feature_importances_'):\n",
    "        return\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:top_n]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.barh(range(len(indices)), importances[indices][::-1], color='skyblue')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices][::-1])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.title(f\"Top {top_n} Feature Importances: {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cache_dir / f\"feature_importance_{model_name.replace(' ','_')}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# --- Model Training & Evaluation ---\n",
    "def model(x, y, target_column=None, top_n=None, save_results=True):\n",
    "    if not np.issubdtype(np.array(y).dtype, np.number):\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(x, y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    models_dict = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        \"SVM\": SVC(probability=True, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "                                 subsample=0.8, colsample_bytree=0.8,\n",
    "                                 eval_metric=\"logloss\", random_state=42, use_label_encoder=False),\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, learning_rate=0.05, random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(iterations=300, learning_rate=0.05,\n",
    "                                       depth=4, verbose=0, random_seed=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "\n",
    "    for name, clf in models_dict.items():\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "        y_proba = clf.predict_proba(X_test_scaled)[:,1] if hasattr(clf,'predict_proba') else None\n",
    "        avg = 'binary' if len(np.unique(y))==2 else 'weighted'\n",
    "        metrics = {\n",
    "            \"Model\": name,\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "            \"Precision\": precision_score(y_test, y_pred, average=avg),\n",
    "            \"Recall\": recall_score(y_test, y_pred, average=avg),\n",
    "            \"F1\": f1_score(y_test, y_pred, average=avg),\n",
    "            \"ROC AUC\": roc_auc_score(y_test, y_proba) if (y_proba is not None and len(np.unique(y))==2) else np.nan\n",
    "        }\n",
    "        results.append(metrics)\n",
    "\n",
    "        # Extra plots\n",
    "        plot_confusion_matrix(y_test, y_pred, name, cache_dir)\n",
    "        if name in [\"Random Forest\",\"XGBoost\",\"LightGBM\",\"CatBoost\"]:\n",
    "            plot_feature_importance(clf, x.columns if hasattr(x,'columns') else np.arange(x.shape[1]), name, cache_dir, top_n=30)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"Balanced Accuracy\", ascending=False)\n",
    "    if save_results and target_column is not None and top_n is not None:\n",
    "        results_df.to_csv(cache_dir / f\"model_results_top{top_n}.csv\", index=False)\n",
    "        plot_model_bars(results_df, cache_dir, top_n)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977ff4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 09:38:31 | INFO | Processing target column: ibd_clinicianmeasure_inactive_active\n",
      "2025-12-03 09:38:31 | INFO | Target 'ibd_clinicianmeasure_inactive_active' has 2 unique values: ['Active' 'Inactive']\n",
      "2025-12-03 09:38:32 | INFO | Found 2488 parquet files\n",
      "2025-12-03 09:39:27 | INFO | Saved feature cache to /home/dsi/linoym/airrport/Thesis/bulk_analysis/cache/biopsy/aho_6RF/ibd_clinicianmeasure_inactive_active/355076c4ca2e/features_top600.pkl\n",
      "/home/ls/linoym/.conda/envs/airrport/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [09:40:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153000\n",
      "[LightGBM] [Info] Number of data points in the train set: 3662, number of used features: 600\n",
      "[LightGBM] [Info] Start training from score -1.098339\n",
      "[LightGBM] [Info] Start training from score -1.098339\n",
      "[LightGBM] [Info] Start training from score -1.099159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ls/linoym/.conda/envs/airrport/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/ls/linoym/.conda/envs/airrport/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-12-03 09:52:01 | INFO | Pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your target column and top_n features\n",
    "    target_column = \"ibd_clinicianmeasure_inactive_active\"   # <-- change to the actual column in your metadata\n",
    "    #demographics_gender\n",
    "    #ibd_disease\n",
    "    #ibd_clinicianmeasure_inactive_active\n",
    "    top_n = 600\n",
    "\n",
    "    # Load metadata\n",
    "    metadata_df = analysis_for_target(target_column)\n",
    "\n",
    "    # Load or compute CDR3 data\n",
    "    cdr3_data = load_cdr3_data(target_column, use_cache=True, parallel=True)\n",
    "\n",
    "    # Create feature matrix\n",
    "    X, y = create_feature_matrix_with_metdata(metadata_df, cdr3_data, top_n=top_n, target_column=target_column)\n",
    "\n",
    "    # Train models and generate plots\n",
    "    X_train, X_test, y_train, y_test, results_df = model(X, y, target_column=target_column, top_n=top_n)\n",
    "\n",
    "    logger.info(\"Pipeline completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5801618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Improved ML pipeline for AIRRPORT CDR3 features\n",
    "Author: Generated for Linoy Menda\n",
    "Date: 2025-12-03\n",
    "\n",
    "Key improvements included:\n",
    "- Normalize CDR3 counts by sample depth\n",
    "- Scale features before SMOTE (SMOTE after scaling)\n",
    "- Stratified cross-validation (with CV metrics)\n",
    "- Feature selection (SelectKBest with mutual information)\n",
    "- Hyperparameter tuning (RandomizedSearchCV) for heavy models\n",
    "- Ensemble VotingClassifier of tuned estimators\n",
    "- SHAP explainability (optional)\n",
    "- Better caching, logging and artifact saving\n",
    "\n",
    "Usage: run as script. Edit CONFIG section to suit paths/targets.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from hashlib import sha1\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import dump\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: SHAP for explainability\n",
    "try:\n",
    "    import shap\n",
    "    _HAS_SHAP = True\n",
    "except Exception:\n",
    "    _HAS_SHAP = False\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "RESOURCE = \"biopsy\"  # biopsy or blood\n",
    "ALGO_VERSION = 'aho_6RF'\n",
    "BASE_PATH = Path(\"/dsi/efroni-lab/AIRRPORT/bulk_IBD\")\n",
    "RESOURCE = RESOURCE.lower()\n",
    "RESOURCE_PATHS = {\n",
    "    \"biopsy\": BASE_PATH / \"biopsy/CDR3_match_results\" / ALGO_VERSION,\n",
    "    \"blood\": BASE_PATH / \"blood/CDR3_match_results\" / ALGO_VERSION,\n",
    "}\n",
    "ALGO_RESULTS_PATH = RESOURCE_PATHS[RESOURCE]\n",
    "METADATA_FILE = ALGO_RESULTS_PATH / f\"metadata_IBD{'_blood' if RESOURCE=='blood' else ''}.csv\"\n",
    "\n",
    "# working dirs\n",
    "WORKDIR = Path.cwd()\n",
    "LOGS_DIR = WORKDIR / \"logs\"\n",
    "CACHE_ROOT = WORKDIR / \"cache\"\n",
    "ARTIFACTS_DIR = WORKDIR / \"artifacts\"\n",
    "for d in (LOGS_DIR, CACHE_ROOT, ARTIFACTS_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# pipeline params (tweakable)\n",
    "TOP_N = 600                 # number of top sequences to use as features\n",
    "FEATURE_SELECT_K = 300      # number of features to keep with SelectKBest\n",
    "CV_FOLDS = 5\n",
    "N_JOBS = -1                 # for RandomizedSearchCV\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---------------- logging ----------------\n",
    "log_file = LOGS_DIR / f\"ml_pipeline_{RESOURCE}_{ALGO_VERSION}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logger = logging.getLogger(\"airrport.improved_pipeline\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if logger.handlers:\n",
    "    for h in list(logger.handlers):\n",
    "        logger.removeHandler(h)\n",
    "fh = logging.FileHandler(log_file)\n",
    "ch = logging.StreamHandler()\n",
    "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\",\"%Y-%m-%d %H:%M:%S\")\n",
    "fh.setFormatter(fmt); ch.setFormatter(fmt)\n",
    "logger.addHandler(fh); logger.addHandler(ch)\n",
    "logger.info(f\"Logging to {log_file}\")\n",
    "\n",
    "# ---------------- utils ----------------\n",
    "\n",
    "def _hash_bytes(b: bytes) -> str:\n",
    "    return sha1(b).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _dir_fingerprint(path: Path, pattern=\"*.parquet\") -> str:\n",
    "    files = sorted(path.glob(pattern))\n",
    "    h = sha1()\n",
    "    for f in files:\n",
    "        try:\n",
    "            stat = f.stat()\n",
    "            h.update(f.name.encode())\n",
    "            h.update(str(stat.st_size).encode())\n",
    "            h.update(str(int(stat.st_mtime)).encode())\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return h.hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _file_fingerprint(f: Path) -> str:\n",
    "    if not f.exists():\n",
    "        return \"no_meta\"\n",
    "    stat = f.stat()\n",
    "    return _hash_bytes(f\"{f.name}:{stat.st_size}:{int(stat.st_mtime)}\".encode())\n",
    "\n",
    "\n",
    "def data_fingerprint() -> str:\n",
    "    p_fp = _dir_fingerprint(ALGO_RESULTS_PATH, \"*.parquet\")\n",
    "    m_fp = _file_fingerprint(METADATA_FILE)\n",
    "    return _hash_bytes(f\"{RESOURCE}|{ALGO_VERSION}|{str(ALGO_RESULTS_PATH)}|{p_fp}|{m_fp}\".encode())\n",
    "\n",
    "\n",
    "def get_cache_dir(target_column: str) -> Path:\n",
    "    fp = data_fingerprint()\n",
    "    d = CACHE_ROOT / RESOURCE / ALGO_VERSION / target_column / fp\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "def save_pickle(p: Path, obj):\n",
    "    with open(p, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_pickle(p: Path):\n",
    "    with open(p, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# ---------------- data loading ----------------\n",
    "\n",
    "def analysis_for_target(target_column: str) -> pd.DataFrame:\n",
    "    logger.info(f\"Loading metadata from {METADATA_FILE}\")\n",
    "    metadata_df = pd.read_csv(METADATA_FILE)\n",
    "    if target_column not in metadata_df.columns:\n",
    "        logger.error(f\"Column {target_column} not in metadata\")\n",
    "        raise KeyError(target_column)\n",
    "    metadata_df = metadata_df.dropna(subset=[target_column])\n",
    "    if metadata_df.shape[0] == 0:\n",
    "        logger.error(\"No samples left after dropping missing target values\")\n",
    "        raise ValueError(\"No samples\")\n",
    "    logger.info(f\"Metadata loaded: {metadata_df.shape[0]} samples with target {target_column}\")\n",
    "    return metadata_df\n",
    "\n",
    "\n",
    "def read_parquet_file(parquet_file_path: Path):\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    sample_name = parquet_file_path.stem.replace('matched_', '').replace('.dedup', '')\n",
    "    cdr3_counts = df.groupby('CDR3_match')['count'].sum().to_dict()\n",
    "    return sample_name, cdr3_counts\n",
    "\n",
    "\n",
    "def load_cdr3_data(target_column: str, use_cache=True, parallel=True) -> dict:\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "    cache_file = cache_dir / \"cdr3_data.pkl\"\n",
    "    if use_cache and cache_file.exists():\n",
    "        logger.info(f\"Loading cached CDR3 data from {cache_file}\")\n",
    "        return load_pickle(cache_file)\n",
    "\n",
    "    parquet_files = list(ALGO_RESULTS_PATH.glob(\"*.parquet\"))\n",
    "    logger.info(f\"Found {len(parquet_files)} parquet files\")\n",
    "    cdr3_data = {}\n",
    "    if parallel:\n",
    "        with ProcessPoolExecutor() as ex:\n",
    "            for sample_name, c in ex.map(read_parquet_file, parquet_files):\n",
    "                cdr3_data[sample_name] = c\n",
    "    else:\n",
    "        for p in parquet_files:\n",
    "            s, c = read_parquet_file(p)\n",
    "            cdr3_data[s] = c\n",
    "    save_pickle(cache_file, cdr3_data)\n",
    "    logger.info(f\"Saved cdr3 cache to {cache_file}\")\n",
    "    return cdr3_data\n",
    "\n",
    "# ---------------- feature matrix ----------------\n",
    "\n",
    "def create_feature_matrix_with_metadata(metadata: pd.DataFrame,\n",
    "                                        cdr3_data: dict,\n",
    "                                        top_n: int = TOP_N,\n",
    "                                        target_column: str = None,\n",
    "                                        use_cache=True):\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "    feat_cache = cache_dir / f\"features_top{top_n}_norm.pkl\"\n",
    "    if use_cache and feat_cache.exists():\n",
    "        logger.info(f\"Loading features from {feat_cache}\")\n",
    "        return load_pickle(feat_cache)\n",
    "\n",
    "    # long-form dataframe\n",
    "    rows = [(s, seq, c) for s, d in cdr3_data.items() for seq, c in d.items() if isinstance(seq, str) and seq.startswith('C')]\n",
    "    df_long = pd.DataFrame(rows, columns=['sample','sequence','count'])\n",
    "    if df_long.empty:\n",
    "        logger.error(\"No CDR3 rows found (maybe different column name)\")\n",
    "        raise ValueError(\"empty cdr3\")\n",
    "\n",
    "    # normalize counts by sample depth to remove sequencing depth bias\n",
    "    total_per_sample = df_long.groupby('sample')['count'].sum().rename('total')\n",
    "    df_long = df_long.join(total_per_sample, on='sample')\n",
    "    df_long['count_norm'] = df_long['count'] / df_long['total']\n",
    "\n",
    "    # pick top sequences by number of samples where they appear\n",
    "    seq_counts_across_samples = df_long.groupby('sequence')['sample'].nunique()\n",
    "    top_sequences = seq_counts_across_samples.nlargest(top_n).index\n",
    "    df_long = df_long[df_long['sequence'].isin(top_sequences)]\n",
    "\n",
    "    x_matrix = df_long.pivot_table(index='sample', columns='sequence', values='count_norm', fill_value=0)\n",
    "\n",
    "    # align metadata\n",
    "    metadata_filtered = metadata[metadata['Run'].isin(x_matrix.index)].copy()\n",
    "    metadata_filtered = metadata_filtered.set_index('Run').loc[x_matrix.index]\n",
    "    y = metadata_filtered[target_column].values\n",
    "\n",
    "    save_pickle(feat_cache, (x_matrix, y))\n",
    "    logger.info(f\"Saved features to {feat_cache}\")\n",
    "    return x_matrix, y\n",
    "\n",
    "# ---------------- plotting helpers ----------------\n",
    "\n",
    "def plot_model_bars(results_df: pd.DataFrame, cache_dir: Path, top_n: int):\n",
    "    df = results_df.copy().sort_values(by=\"Balanced Accuracy\", ascending=False)\n",
    "    plt.figure(figsize=(10,4.5))\n",
    "    palette = sns.color_palette('pastel', n_colors=len(df))\n",
    "    bars = plt.bar(df['Model'], df['Balanced Accuracy'], color=palette)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0,1)\n",
    "    plt.ylabel('Balanced Accuracy')\n",
    "    plt.title(f'Balanced Accuracy by model (top{top_n})')\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, h + 0.01, f\"{h:.3f}\", ha='center')\n",
    "    plt.tight_layout(); plt.savefig(cache_dir / f\"balanced_accuracy_top{top_n}.png\", dpi=150); plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, cache_dir: Path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title(f'Confusion: {model_name}')\n",
    "    plt.tight_layout(); plt.savefig(cache_dir / f\"confusion_{model_name.replace(' ','_')}.png\", dpi=150); plt.close()\n",
    "\n",
    "# ---------------- modeling ----------------\n",
    "\n",
    "def evaluate_model(clf, X, y, cv=CV_FOLDS, scoring='balanced_accuracy'):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X, y, scoring=scoring, cv=skf, n_jobs=N_JOBS)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def tune_model_randomized(clf, param_distributions, X, y, cv=CV_FOLDS, n_iter=25):\n",
    "    rs = RandomizedSearchCV(\n",
    "        clf,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        scoring='balanced_accuracy',\n",
    "        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE),\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0\n",
    "    )\n",
    "    rs.fit(X, y)\n",
    "    return rs\n",
    "\n",
    "\n",
    "def build_and_evaluate(X, y, target_column: str, feature_names=None, save_artifacts=True):\n",
    "    cache_dir = get_cache_dir(target_column)\n",
    "\n",
    "    # label encode target if necessary\n",
    "    if not np.issubdtype(np.array(y).dtype, np.number):\n",
    "        le = LabelEncoder(); y_enc = le.fit_transform(y)\n",
    "    else:\n",
    "        y_enc = y\n",
    "\n",
    "    # split once for final hold-out evaluation (stratified)\n",
    "    X_train_full, X_hold, y_train_full, y_hold = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=RANDOM_STATE)\n",
    "\n",
    "    # scale BEFORE SMOTE\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_full)\n",
    "    X_hold_scaled = scaler.transform(X_hold)\n",
    "\n",
    "    # SMOTE on scaled training data\n",
    "    sm = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_res, y_res = sm.fit_resample(X_train_scaled, y_train_full)\n",
    "    logger.info(f\"After SMOTE: {Counter(y_res)}\")\n",
    "\n",
    "    # Feature selection on resampled data\n",
    "    selector = SelectKBest(mutual_info_classif, k=min(FEATURE_SELECT_K, X_res.shape[1]))\n",
    "    X_res_sel = selector.fit_transform(X_res, y_res)\n",
    "    X_hold_sel = selector.transform(X_hold_scaled)\n",
    "    selected_features = None\n",
    "    if feature_names is not None:\n",
    "        selected_features = np.array(feature_names)[selector.get_support()]\n",
    "\n",
    "    # simple candidate models\n",
    "    candidates = {\n",
    "        'logreg_l1': LogisticRegression(penalty='l1', solver='liblinear', max_iter=2000, random_state=RANDOM_STATE),\n",
    "        'rf': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        'xgb': XGBClassifier(n_estimators=200, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE),\n",
    "        'lgb': LGBMClassifier(n_estimators=200, learning_rate=0.05, random_state=RANDOM_STATE)\n",
    "    }\n",
    "\n",
    "    # quick CV baseline\n",
    "    results = []\n",
    "    for name, clf in candidates.items():\n",
    "        try:\n",
    "            scores = evaluate_model(clf, X_res_sel, y_res, cv=CV_FOLDS)\n",
    "            results.append({'Model': name, 'CV_BalAcc_Mean': scores.mean(), 'CV_BalAcc_STD': scores.std()})\n",
    "            logger.info(f\"{name}: CV balanced acc {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed CV for {name}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values('CV_BalAcc_Mean', ascending=False)\n",
    "\n",
    "    # Hyperparameter tuning for top candidates (rf and xgb)\n",
    "    tuned = {}\n",
    "    # Random Forest tuning\n",
    "    rf_params = {\n",
    "        'n_estimators': [200, 400, 600],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 4, 8]\n",
    "    }\n",
    "    logger.info('Tuning RandomForest...')\n",
    "    rf_search = tune_model_randomized(RandomForestClassifier(random_state=RANDOM_STATE), rf_params, X_res_sel, y_res, n_iter=8)\n",
    "    tuned['rf'] = rf_search.best_estimator_\n",
    "    logger.info(f\"RF best: {rf_search.best_score_:.3f}, params: {rf_search.best_params_}\")\n",
    "\n",
    "    # XGBoost tuning\n",
    "    xgb_params = {\n",
    "        'n_estimators': [200, 400],\n",
    "        'max_depth': [3, 4, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "    logger.info('Tuning XGBoost...')\n",
    "    xgb_search = tune_model_randomized(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE), xgb_params, X_res_sel, y_res, n_iter=8)\n",
    "    tuned['xgb'] = xgb_search.best_estimator_\n",
    "    logger.info(f\"XGB best: {xgb_search.best_score_:.3f}, params: {xgb_search.best_params_}\")\n",
    "\n",
    "    # LightGBM quick tuning\n",
    "    lgb_params = {\n",
    "        'n_estimators': [200, 400],\n",
    "        'num_leaves': [31, 63],\n",
    "        'learning_rate': [0.01, 0.05]\n",
    "    }\n",
    "    logger.info('Tuning LightGBM...')\n",
    "    lgb_search = tune_model_randomized(LGBMClassifier(random_state=RANDOM_STATE), lgb_params, X_res_sel, y_res, n_iter=6)\n",
    "    tuned['lgb'] = lgb_search.best_estimator_\n",
    "    logger.info(f\"LGB best: {lgb_search.best_score_:.3f}, params: {lgb_search.best_params_}\")\n",
    "\n",
    "    # Build ensemble of tuned models\n",
    "    estimators = [('rf', tuned['rf']), ('xgb', tuned['xgb']), ('lgb', tuned['lgb'])]\n",
    "    ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "    logger.info('Fitting ensemble on resampled & selected features...')\n",
    "    ensemble.fit(X_res_sel, y_res)\n",
    "\n",
    "    # Evaluate on holdout\n",
    "    y_hold_pred = ensemble.predict(X_hold_sel)\n",
    "    y_hold_proba = ensemble.predict_proba(X_hold_sel) if hasattr(ensemble, 'predict_proba') else None\n",
    "    avg = 'binary' if len(np.unique(y_enc)) == 2 else 'weighted'\n",
    "    metrics = {\n",
    "        'Balanced Accuracy': balanced_accuracy_score(y_hold, y_hold_pred),\n",
    "        'Precision': precision_score(y_hold, y_hold_pred, average=avg, zero_division=0),\n",
    "        'Recall': recall_score(y_hold, y_hold_pred, average=avg, zero_division=0),\n",
    "        'F1': f1_score(y_hold, y_hold_pred, average=avg, zero_division=0),\n",
    "        'ROC AUC': roc_auc_score(y_hold, y_hold_proba[:,1]) if (y_hold_proba is not None and len(np.unique(y_enc))==2) else np.nan\n",
    "    }\n",
    "    logger.info(f\"Holdout metrics: {metrics}\")\n",
    "\n",
    "    # save artifacts\n",
    "    if save_artifacts:\n",
    "        model_path = cache_dir / 'ensemble.joblib'\n",
    "        dump(ensemble, model_path)\n",
    "        dump(scaler, cache_dir / 'scaler.joblib')\n",
    "        save_pickle(cache_dir / 'selected_features.pkl', selected_features.tolist() if selected_features is not None else None)\n",
    "        results_df.to_csv(cache_dir / 'cv_baseline_results.csv', index=False)\n",
    "        with open(cache_dir / 'holdout_metrics.json', 'w') as fh:\n",
    "            json.dump(metrics, fh, indent=2)\n",
    "        logger.info(f\"Artifacts saved to {cache_dir}\")\n",
    "\n",
    "    # confusion plot\n",
    "    plot_confusion_matrix(y_hold, y_hold_pred, 'ensemble_holdout', cache_dir)\n",
    "\n",
    "    # SHAP explanation (tree-based explainer recommended)\n",
    "    if _HAS_SHAP:\n",
    "        try:\n",
    "            logger.info('Computing SHAP values (this can take time)')\n",
    "            explainer = shap.Explainer(tuned['xgb'])\n",
    "            shap_values = explainer(X_hold_sel)\n",
    "            shap.summary_plot(shap_values, features=X_hold_sel, feature_names=selected_features, show=False)\n",
    "            plt.tight_layout(); plt.savefig(cache_dir / 'shap_summary.png', dpi=150); plt.close()\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"SHAP failed: {e}\")\n",
    "\n",
    "    # return objects useful for further analysis\n",
    "    return {\n",
    "        'ensemble': ensemble,\n",
    "        'scaler': scaler,\n",
    "        'selector': selector,\n",
    "        'selected_features': selected_features,\n",
    "        'holdout_metrics': metrics,\n",
    "        'cv_baseline': results_df\n",
    "    }\n",
    "\n",
    "# ---------------- main ----------------\n",
    "if __name__ == '__main__':\n",
    "    target_column = 'demographics_gender'  # change as needed\n",
    "\n",
    "    # load metadata\n",
    "    metadata = analysis_for_target(target_column)\n",
    "\n",
    "    # load cdr3 data\n",
    "    cdr3_data = load_cdr3_data(target_column, use_cache=True, parallel=True)\n",
    "\n",
    "    # create feature matrix (normalized counts)\n",
    "    X_df, y = create_feature_matrix_with_metadata(metadata, cdr3_data, top_n=TOP_N, target_column=target_column, use_cache=True)\n",
    "\n",
    "    logger.info(f\"Feature matrix shape: {X_df.shape}\")\n",
    "\n",
    "    # run modeling\n",
    "    out = build_and_evaluate(X_df.values, y, target_column=target_column, feature_names=X_df.columns)\n",
    "\n",
    "    logger.info('Pipeline finished')\n",
    "    logger.info(f\"Holdout metrics: {out['holdout_metrics']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airrport",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
